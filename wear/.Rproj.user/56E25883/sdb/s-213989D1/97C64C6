{
    "contents" : " \n\n#######################################################################################################\n#######################################################################################################\nlibrary(reldist)  ###compute gini index\n#######################################################################################################\n########################################## Group Information ##########################################\n#######################################################################################################\nimport.APST.csvfile.groups<- read.csv(\"C:\\\\Yukun\\\\Sarah'sProject_Haocheng\\\\STARTgroups.csv\")\n################################################ Set Folder     ##################################### \nfolder.to.export.APST.csvfile.and.RDatafile<- \"C:\\\\Yukun\\\\Sarah'sProject_Haocheng\"\nfolder.to.import.APST.csvfile.week0<- \"C:\\\\Yukun\\\\Sarah'sProject_Haocheng\\\\event files\\\\baseline\"\nfolder.to.import.APST.csvfile.week3<- \"C:\\\\Yukun\\\\Sarah'sProject_Haocheng\\\\event files\\\\three\"\nfolder.to.import.APST.csvfile.week6<- \"C:\\\\Yukun\\\\Sarah'sProject_Haocheng\\\\event files\\\\six\"\nfolder.to.import.APST.csvfile.week9<- \"C:\\\\Yukun\\\\Sarah'sProject_Haocheng\\\\event files\\\\nine\"\nfolder.to.import.APST.csvfile.week12<- \"C:\\\\Yukun\\\\Sarah'sProject_Haocheng\\\\event files\\\\twelve\"\n#############################################\n\nfor (www in c(0,3,6,9,12))\n{\n#### www=0\nSummary.Statistics.Table<-c()\nif(www==0) {week=0; setwd(folder.to.import.APST.csvfile.week0);takeoff.time<-read.csv(\"baseline.on.off.final.csv\");bed.time<-read.csv(\"baseline.bed.final.csv\")}\nif(www==3){week=3; setwd(folder.to.import.APST.csvfile.week3);takeoff.time<-read.csv(\"week3.on.off.final.csv\");bed.time<-read.csv(\"week3.bed.final.csv\") }\nif(www==6){week=6; setwd(folder.to.import.APST.csvfile.week6);takeoff.time<-read.csv(\"week6.on.off.final.csv\");bed.time<-read.csv(\"week6.bed.final.csv\") }\nif(www==9){week=9; setwd(folder.to.import.APST.csvfile.week9);takeoff.time<-read.csv(\"week9.on.off.final.csv\");bed.time<-read.csv(\"week9.bed.final.csv\") }\nif(www==12){week=12;setwd(folder.to.import.APST.csvfile.week12);takeoff.time<-read.csv(\"week12.on.off.final.csv\");bed.time<-read.csv(\"week12.bed.final.csv\") }\n\nfor (person in 1:2)\n {\n#######################################################read data\n######## person<-1\nid<-person\nif(nchar(id)==1) id.char<-paste(\"0\",id,sep=\"\") else  id.char<-as.character(id)\n#a<-try(eval(parse(text=paste(\"dat<-read.csv('APST\",id.char,\"W12_event.csv')\",sep=\"\"))))\nif(week==0)a<-try(eval(parse(text=paste(\"dat<-read.csv('APST\",id.char,\"B_event.csv')\",sep=\"\")))) else a<-try(eval(parse(text=paste(\"dat<-read.csv('APST\",id.char,\"W\",week,\"_event.csv')\",sep=\"\"))))\nif(class(a)==\"try-error\") next\n\n#######################################################build record's begin and end time from log file/// May not be true!// trust data only\nrecord<-subset(takeoff.time,takeoff.time$id==person)\n\n###\nif(nrow(record)==0)next\n###\nrecord.start.time<-c()\nrecord.end.time<-c()\nfor (kk in 1:nrow(record))\n{\ntemp.start.time<-as.numeric(as.POSIXlt(strptime(as.character(paste(as.character(record[kk,3] ),as.character(record[kk,4]))),\"%m/%d/%Y %H:%M:%S\"))+2209136400)/24/60/60\nrecord.start.time<-c(record.start.time,temp.start.time)       \n\ntemp.end.time<-as.numeric(as.POSIXlt( strptime(as.character(paste(as.character(record[kk,5] ),as.character(record[kk,6]))),\"%m/%d/%Y %H:%M:%S\")  )+2209136400)/24/60/60\nrecord.end.time<-c(record.end.time,temp.end.time) \n}\n##########################################  match get up time with take on time/// if multiple take on time in a day, the second take on time is seen as get up time\n#####list days take on\n#####time.char<-as.numeric(format(as.POSIXlt(record.start.time*24*60*60, origin = ISOdatetime(1899,12,30,0,0,0) ),\"%d\"))\n###\nrecord.getup<-subset(bed.time,bed.time$id==person)\n###\nrecord.getup.time<-c()\nrecord.sleep.time<-c()\nfor (kk in 1:nrow(record.getup))\n{\ntemp.getup.time<-as.numeric(as.POSIXlt(strptime(as.character(paste(as.character(record.getup[kk,3] ),as.character(record.getup[kk,4]))),\"%m/%d/%Y %H:%M:%S\"))+2209136400)/24/60/60\nrecord.getup.time<-c(record.getup.time,temp.getup.time)\ntemp.sleep.time<-as.numeric(as.POSIXlt(strptime(as.character(paste(as.character(record.getup[kk,5] ),as.character(record.getup[kk,6]))),\"%m/%d/%Y %H:%M:%S\"))+2209136400)/24/60/60\nrecord.sleep.time<-c(record.sleep.time,temp.sleep.time)\n}\n#######################################################\n##########################################  match get up time with take on time/// if multiple take on time in a day, the second take on time is seen as get up time\n#######################################################\n####################################################### Unify date structure  delete \nprint(is.numeric(dat$Time))\nif(is.numeric(dat$Time)==F) ####if  is.numeric(dat$Time)==F, we need further modification of time in next step\n{\nee<-as.character(dat$Time)\nmax.length<-max(nchar(ee))\nprint(max.length)\nee[nchar(ee)!=max.length]<-\"#1899-12-30 00:00:00#\"\n#### use character type, may not be good\nee.new<- (as.numeric( as.POSIXlt( substr(ee, 2, max.length-1 )  )    )+2209136400)/24/60/60\n#### use interval type, this is the best\nstart.ee<-  min(which(dat[,2]>0))-1\nprint(start.ee)\nee.new.int.type <-c( ee.new[1:((start.ee)-1)],ee.new[start.ee]+(dat$DataCount[start.ee:nrow(dat)]/10/24/60/60)  )\n#### if interval type has large difference with character type, use character type\nint.dif.char<-which(abs(ee.new-ee.new.int.type)>0.1 )\nee.new.int.type[int.dif.char]<-ee.new[int.dif.char]\n####\ndat<-cbind(ee.new.int.type,dat[,2:6])  \n}\n \ndat<- dat[,1:6]  #### this works for both time good and bad data\n#######################################################  delete wrong data, al records should between log time for take on and take off\n#######################################################  For the case that start in log time but last long outside the log, we just leave the time in the interval\nfinal.dat<-do.call(rbind,sapply( 1: length(record.start.time),function(ll){\ntemp.mat<-subset(dat,dat[,1]+dat[,3]/24/60/60>record.start.time[ll] & dat[,1]<record.end.time[ll] )\nif(nrow(temp.mat)==0) return (NULL)  \n    if(temp.mat[nrow(temp.mat),1]+(temp.mat[nrow(temp.mat),3]/24/60/60)> record.end.time[ll])  ###if this activity is the last one and it surpass the take off log time\n      {\n      temp.mat[nrow(temp.mat),6]<-temp.mat[nrow(temp.mat),6]*(record.end.time[ll]-temp.mat[nrow(temp.mat),1])/(temp.mat[nrow(temp.mat),3]/24/60/60)\n      temp.mat[nrow(temp.mat),3]<- (record.end.time[ll]-temp.mat[nrow(temp.mat),1])*24*60*60\n      }\n    if(temp.mat[1,1]<record.start.time[ll])   ###if this activity is the first one and itis earlier than the take on log time\n      {\n        temp.mat[1,6]<-temp.mat[1,6]* (temp.mat[1,3]-(record.start.time[ll]- temp.mat[1,1])*24*60*60)/temp.mat[1,3]\n        temp.mat[1,3]<-temp.mat[1,3]-(record.start.time[ll]- temp.mat[1,1])*24*60*60  \n        temp.mat[1,1]<-record.start.time[ll]\n      }\n\n return(temp.mat)\n}, simplify = F)) \n \n \n \nif(length(final.dat)==0)next\n#######################################################\n####################################################### Dataset with Records\n\nfinal.dat<-final.dat[,c(1,3,4,6)]\ncolnames(final.dat)<-c(\"date.time\",\"Interval\",\"ActivityCode\", \"METs\")\nif(is.numeric(dat[,1])==T) eval(parse(text=paste(\"APST\",id.char,\"week\",week,\"<-final.dat\",sep=\"\"))) else   next \n#######################################################\n####################################################### Summary Statistics\n#######################################################\n  for (ll in 1: length(record.getup.time) )\n{\n## ll=1\ntemp.mat<-subset(final.dat,final.dat[,1]>record.getup.time[ll] & final.dat[,1]<record.sleep.time[ll] )\nif(nrow(temp.mat)==0)next\n###################################################\ntime.char<-as.POSIXlt(record.getup.time[ll]*24*60*60, origin = ISOdatetime(1899,12,30,0,0,0))\nhour.char<-as.numeric(format(as.POSIXlt(temp.mat$date.time*24*60*60, origin = ISOdatetime(1899,12,30,0,0,0)),\"%H\"))\n###\ntemp.sed<-subset(temp.mat,temp.mat$ActivityCode==0)$Interval\nlength.temp.sed<-length(temp.sed)\n###################################################\n###################################################\n################################################### For Table part 1 evan_final_2_23\n###################################################\n### group\ngroup.char<- as.character(subset(import.APST.csvfile.groups,id==person)$group)\nif (length(group.char)==0) group.char<- NA                                                                    ##### some id does not have group\n###\ntime.char<-as.POSIXlt(record.getup.time[ll]*24*60*60, origin = ISOdatetime(1899,12,30,0,0,0))\nmonth<-as.numeric(format(time.char,\"%m\"))\nday<-as.numeric(format(time.char,\"%d\"))\nyear<-as.numeric(format(time.char,\"%Y\"))\nhours.worn.total<- sum(temp.mat$Interval)/60/60\nhours.awake<- (record.sleep.time[ll]-record.getup.time[ll])*24\nsed.hour<- sum(temp.sed) /60/60\nstand.hour<- sum(subset(temp.mat,temp.mat$ActivityCode==1)$Interval) /60/60\nstep.hour<- sum(subset(temp.mat,temp.mat$ActivityCode==2)$Interval) /60/60\nnum.changes.from.sed.to.non.sed<- length.temp.sed\n######## Code update here !\nstep.count.total<- 2*nrow(subset(temp.mat,temp.mat$ActivityCode==2))  ##### in the event file, one row with ActivityCode==2 means two steps\n########\ngini.index<- gini(temp.sed)\nnum.hour.over.3.METs<-  sum(temp.mat$Interval[(temp.mat$METs/temp.mat$Interval)*60*60>3])/60/60\nMET.hours<- sum(temp.mat$METs)\nvalid.day<-ifelse( (hours.worn.total<10 & hours.worn.total/hours.awake>0.8 & step.count.total>200) | (hours.worn.total>=10 & step.count.total>200 ),1,0    )\ndayofweek<-as.numeric(format(time.char,\"%w\"))\nweekday.or.weekend<- ifelse( dayofweek!=0 & dayofweek!=6,1,0)\n\ntable1<-c(person,group.char,www,month,day,year,hours.worn.total,hours.awake,sed.hour,stand.hour,step.hour,num.changes.from.sed.to.non.sed,step.count.total,gini.index,num.hour.over.3.METs,MET.hours,valid.day,dayofweek,weekday.or.weekend)\n\ntable1.label<-c(\"id\",\"group\",\"week\",\"month\",\"day\",\"year\",\"hours.worn.total\",\"hours.awake\",\"sed.hour\",\"stand.hour\",\"step.hour\",\"num.changes.from.sed.to.non.sed\",\"step.count.total\",\"gini.index\",\"num.hour.over.3.METs\",\"MET.hours\",\"valid.day\",\"dayofweek\",\"weekday.or.weekend\")\n\n###################################################\n################################################### For Table part 2  Doc to fill\n###################################################\ntotal.sed.time<-sed.hour\ntotal.number.of.sed.bouts<-num.changes.from.sed.to.non.sed\nmean.sed.bout.length<- mean(temp.sed) /60/60\nprop.of.sed.time.greater.20min<- 100*length(temp.sed[temp.sed>20*60])/length.temp.sed\nprop.of.sed.time.greater.60min<- 100*length(temp.sed[temp.sed>60*60])/length.temp.sed\nprop.of.sed.time.greater.120min<- 100*length(temp.sed[temp.sed>120*60])/length.temp.sed\n\ntotal.sed.time.greater.20min<- sum(temp.sed[temp.sed>20*60])/60/60\ntotal.sed.time.greater.60min<- sum(temp.sed[temp.sed>60*60])/60/60\ntotal.sed.time.greater.120min<- sum(temp.sed[temp.sed>120*60])/60/60\n\nquantile.temp<-quantile(temp.sed, probs = c(0.05,0.25,0.5,0.75,0.95))/60/60\npercentile.sed.time.5<- quantile.temp[1]\npercentile.sed.time.25<- quantile.temp[2]\npercentile.sed.time.50<- quantile.temp[3]\npercentile.sed.time.75<- quantile.temp[4]\npercentile.sed.time.95<- quantile.temp[5]\n\nalpha.sed<- 1+ 1/mean(log(temp.sed/ min(temp.sed)))\ngini.index.sed<- gini.index\n\nprop.sed.time.6.12<- 100*sum(subset(temp.mat,temp.mat$ActivityCode==0 & hour.char>=6 & hour.char<12)$Interval) /(sum(subset(temp.mat,hour.char>=6 & hour.char<12)$Interval)+0.0001)   ###prevent this value is zero\nprop.sed.time.12.18<- 100*sum(subset(temp.mat,temp.mat$ActivityCode==0 & hour.char>=12 & hour.char<18)$Interval) /(sum(subset(temp.mat,hour.char>=12 & hour.char<18)$Interval)+0.0001)\nprop.sed.time.18.22<- 100*sum(subset(temp.mat,temp.mat$ActivityCode==0 & hour.char>=18 & hour.char<22)$Interval) /(sum(subset(temp.mat,hour.char>=18 & hour.char<22)$Interval)+0.0001)\n \n\ntable2<-c(88888888,total.sed.time,total.number.of.sed.bouts,mean.sed.bout.length,prop.of.sed.time.greater.20min,prop.of.sed.time.greater.60min,prop.of.sed.time.greater.120min,total.sed.time.greater.20min,total.sed.time.greater.60min,total.sed.time.greater.120min,percentile.sed.time.5,percentile.sed.time.25,percentile.sed.time.50,percentile.sed.time.75,percentile.sed.time.95,alpha.sed,gini.index.sed,prop.sed.time.6.12,prop.sed.time.12.18,prop.sed.time.18.22)\ntable2.label<-c(\"88888888\",\"total.sed.time\",\"total.number.of.sed.bouts\",\"mean.sed.bout.length\" ,\"prop.of.sed.time.greater.20min\",\"prop.of.sed.time.greater.60min\",\"prop.of.sed.time.greater.120min\",\"total.sed.time.greater.20min\",\"total.sed.time.greater.60min\",\"total.sed.time.greater.120min\",\"percentile.sed.time.5\",\"percentile.sed.time.25\",\"percentile.sed.time.50\",\"percentile.sed.time.75\",\"percentile.sed.time.95\",\"alpha.sed\",\"gini.index.sed\",\"prop.sed.time.6.12\",\"prop.sed.time.12.18\",\"prop.sed.time.18.22\")\n###################################################\n################################################### For Table part 3  Sarah's table\n###################################################\n\nperc.sedentary<- 100*sed.hour/hours.worn.total\nperc.stand<- 100*stand.hour/hours.worn.total\nperc.step<- 100*step.hour/hours.worn.total\nstep.per.day<-step.count.total\nbreak.per.day<-num.changes.from.sed.to.non.sed\nbreak.rate<-break.per.day/sed.hour\nMET.hour<- MET.hours\n\ntable3<- c(88888888,perc.sedentary,perc.stand,perc.step,step.per.day,break.per.day,break.rate,MET.hour) \ntable3.label<- c(\"88888888\",\"perc.sedentary\",\"perc.stand\",\"perc.step\",\"step.per.day\",\"break.per.day\",\"break.rate\",\"MET.hour\")\n\n###################################################\n################################################### Calculate Activity information\n###################################################\n### for standing and stepping, we have to combine the data \n### since this is for activity, we take standing and stepping as the same activity\n############### start and ends of each runs\ntemp.mat.for.activity<- temp.mat\ntemp.mat.for.activity$Activity[temp.mat.for.activity$Activity==1]<-2\nend.pos<-cumsum(rle(temp.mat.for.activity$Activity)$lengths)\nstart.pos<-c(0,end.pos[1:(length(end.pos)-1)])+1\n############### for each runs, handle the data\nhandle.runs<- sapply(1:length(end.pos),function(x,data.mat=temp.mat.for.activity) \n{\n  select.data<-data.mat[start.pos[x]:end.pos[x],]\n  combine.data<- c(min(select.data$date.time),sum(select.data$Interval),max(select.data$Activity),sum(select.data$METs) )   \n  return(combine.data)\n}, simplify=F\n   )\n############### combine each run\ncombined.temp.mat.for.activity<-data.frame(do.call(rbind,handle.runs))\ncolnames(combined.temp.mat.for.activity)<-c(\"date.time\", \"Interval\", \"ActivityCode\",\"METs\")\n###############\n###############Calculation\n###############\n###\ntemp.activity<-subset(combined.temp.mat.for.activity,combined.temp.mat.for.activity$ActivityCode==2)$Interval\n###\n \nlength.temp.activity<-length(temp.activity)\ntotal.number.of.activity.bouts<- length.temp.activity\nmean.activity.bout.length<- mean(temp.activity) /60/60\n\nprop.of.activity.time.greater.5min<- 100*length(temp.activity[temp.activity>5*60])/length.temp.activity\nprop.of.activity.time.greater.10min<- 100*length(temp.activity[temp.activity>10*60])/length.temp.activity\nprop.of.activity.time.greater.30min<- 100*length(temp.activity[temp.activity>30*60])/length.temp.activity\n\ntotal.activity.time.greater.5min<- sum(temp.activity[temp.activity>5*60])/60/60\ntotal.activity.time.greater.10min<- sum(temp.activity[temp.activity>10*60])/60/60\ntotal.activity.time.greater.30min<- sum(temp.activity[temp.activity>30*60])/60/60\n\nquantile.activity.temp<-quantile(temp.activity, probs = c(0.05,0.25,0.5,0.75,0.95))/60/60\npercentile.activity.time.5<- quantile.activity.temp[1]\npercentile.activity.time.25<- quantile.activity.temp[2]\npercentile.activity.time.50<- quantile.activity.temp[3]\npercentile.activity.time.75<- quantile.activity.temp[4]\npercentile.activity.time.95<- quantile.activity.temp[5]\n\nalpha.activity<- 1+ 1/mean(log(temp.activity/ min(temp.activity)))\ngini.index.activity<- gini(temp.activity)\n \nstepping.to.standing.ratio<- step.hour/stand.hour\n\ntable4<- c(88888888,total.number.of.activity.bouts,mean.activity.bout.length,prop.of.activity.time.greater.5min,prop.of.activity.time.greater.10min,prop.of.activity.time.greater.30min,total.activity.time.greater.5min,total.activity.time.greater.10min,total.activity.time.greater.30min,percentile.activity.time.5,percentile.activity.time.25,percentile.activity.time.50,percentile.activity.time.75,percentile.activity.time.95,alpha.activity,gini.index.activity,stepping.to.standing.ratio) \ntable4.label<- c(\"88888888\",\"total.number.of.activity.bouts\",\"mean.activity.bout.length\",\"prop.of.activity.time.greater.5min\",\"prop.of.activity.time.greater.10min\",\"prop.of.activity.time.greater.30min\",\"total.activity.time.greater.5min\",\"total.activity.time.greater.10min\",\"total.activity.time.greater.30min\",\"percentile.activity.time.5\",\"percentile.activity.time.25\",\"percentile.activity.time.50\",\"percentile.activity.time.75\",\"percentile.activity.time.95\",\"alpha.activity\",\"gini.index.activity\",\"stepping.to.standing.ratio\")\n####################\n################################################################################################\n###################################################Calculate MVPA information##################\n################################################################################################\n############################################################\n############################################################ step 1, build 1min intervals.\n############################################################\n### The default X interval is 1 min/ the suggested intervals can be 30s, 10s\n###\nmvpa.sporadic.interval<- 1/4          ### 1 means 1 minute; 0.5 means 30 seconds; 1/6 means 10 seconds\n\n\nmvpa.1min.mat<-temp.mat\nstart.time<-mvpa.1min.mat$date.time[1]\nend.time<-  mvpa.1min.mat$date.time[nrow(mvpa.1min.mat)]\nnum.1min.interval<- trunc( (end.time-start.time)*24*60*60/(60*mvpa.sporadic.interval) )   ###point 1\n#(end.time-start.time) != sum(temp.mat$Interval)/60/60/24 if there is take off \ninterval.length<-mvpa.sporadic.interval*60/60/60/24\ninterval.1min.start<-start.time+interval.length*(1:(num.1min.interval))\n################## \nmvpa.record.start.time<-c(start.time, interval.1min.start)\nmvpa.record.end.time<-c(interval.1min.start,end.time)\n################## if there is take off, they won't be in combine.original.pseudo.mat\ncombine.original.pseudo.mat<-do.call(rbind,sapply(1: length(mvpa.record.start.time),function(ll){\ntemp.mat<-subset(mvpa.1min.mat,mvpa.1min.mat[,1]+mvpa.1min.mat[,2]/24/60/60>mvpa.record.start.time[ll] & mvpa.1min.mat[,1]<mvpa.record.end.time[ll] )\nif(nrow(temp.mat)==0) return (NULL)    \n    if(temp.mat[nrow(temp.mat),1]+(temp.mat[nrow(temp.mat),2]/24/60/60)> mvpa.record.end.time[ll])  ###if this activity is the last one and it surpass the take off log time\n      {\n      temp.mat[nrow(temp.mat),4]<-temp.mat[nrow(temp.mat),4]*(mvpa.record.end.time[ll]-temp.mat[nrow(temp.mat),1])/(temp.mat[nrow(temp.mat),2]/24/60/60)\n      temp.mat[nrow(temp.mat),2]<- (mvpa.record.end.time[ll]-temp.mat[nrow(temp.mat),1])*24*60*60\n      }\n    if(temp.mat[1,1]<mvpa.record.start.time[ll])   ###if this activity is the first one and itis earlier than the take on log time\n      {\n        temp.mat[1,4]<-temp.mat[1,4]* (temp.mat[1,2]-(mvpa.record.start.time[ll]- temp.mat[1,1])*24*60*60)/temp.mat[1,2]\n        temp.mat[1,2]<-temp.mat[1,2]-(mvpa.record.start.time[ll]- temp.mat[1,1])*24*60*60  \n        temp.mat[1,1]<-mvpa.record.start.time[ll]\n      }\n\n return(cbind(temp.mat,ll))\n}, simplify = F)  )   \n\ncolnames(combine.original.pseudo.mat)<-c(\"date.time\",\"Interval\",\"ActivityCode\", \"METs\",\"one.minute.interval\") \n############################################################\n############################################################ step2 summary 1 min intervals\n############################################################\none.minute.collection<-by(combine.original.pseudo.mat,combine.original.pseudo.mat$one.minute.interval,function(s)c(min(s$date.time),sum(s$METs)*(60/mvpa.sporadic.interval),unique(s$one.minute.interval),sum(s$Interval)  )) ###point 3\none.minute.mat<-do.call(rbind,one.minute.collection)\none.minute.mat<-subset(one.minute.mat,one.minute.mat[,3]!=0 & one.minute.mat[,4]>(60*mvpa.sporadic.interval*0.9) & one.minute.mat[,4]<(60*mvpa.sporadic.interval*1.1)     )  ### one.minute.mat[,4] is the true length, it may not be exactly 30 second, can have a few seconds bias \n#########################  \nif(trunc(nrow(one.minute.mat)/(10/mvpa.sporadic.interval))==0)  {\nten.minute.vec<-rep(1,nrow(one.minute.mat))\nif(nrow(one.minute.mat)==1) ten.minute.mat<- data.frame(t(c(one.minute.mat[1:length(ten.minute.vec),],ten.minute.vec)))\nif(nrow(one.minute.mat)>1) ten.minute.mat<- data.frame(cbind(one.minute.mat[1:length(ten.minute.vec),],ten.minute.vec))\n} else\n{ \nten.minute.vec<-rep(1:trunc(nrow(one.minute.mat)/(10/mvpa.sporadic.interval)),each=  (10/mvpa.sporadic.interval)    )    ##### 30s to 10 min ###point 4\nten.minute.mat<- data.frame(cbind(one.minute.mat[1:length(ten.minute.vec),],ten.minute.vec))\n}\n\ncolnames(ten.minute.mat)<-c(\"date.time\",\"mets\",\"one.minute.interval\",\"interval.length\",\"ten.minute.interval\")\n############################################################\n############################################################ step3 summary 10 min intervals\n############################################################\n#### if in 10 minutes, 8 minutes have METs>3, it is MVPA bout; if less than 8minutes, they are counted as mvpa sporadic.\nis.mvpa<-function(s) if(s>=(8/mvpa.sporadic.interval)    ) return(1) else return(0)   ###point 5  ### this is for MVPA long bout\nten.minute.collection<- data.frame(do.call(rbind,by(ten.minute.mat,ten.minute.mat$ten.minute.interval,function(s)c(min(s$date.time), is.mvpa(length(which(s$mets>=3))), mean(s$mets),length(which(s$mets>=3)), abs(max(s$date.time)-min(s$date.time)-sum(s$interval.length[1:(length(s$interval.length)-1)])/24/60/60 )   ))))\ncolnames(ten.minute.collection)<-c(\"date.time\",\"mvpa\",\"mets\",\"mvpa.sporadic\",\"is.interval.valid\")  #### is.interval.valid is to avoid the wear off during the day problem\nten.minute.collection<-subset(ten.minute.collection,is.interval.valid<0.003) ###if the interval has 5 minutes take off, we do not take it \n\n############################################################\n############################################################ step4 MVPA information\n############################################################ \n#### total time\nTotal.MVPA.Long.Bout.time<-nrow(subset(ten.minute.collection,mvpa==1))/6  ###by hours\nTotal.MVPA.Sporadic.time<-sum(subset(ten.minute.collection,mvpa.sporadic>0 & mvpa!=1)$mvpa.sporadic )/(60/mvpa.sporadic.interval) ###by hours ###point 6\nTotal.MVPA.time<- Total.MVPA.Long.Bout.time+Total.MVPA.Sporadic.time\nTotal.light.time<- sum(temp.activity) /60/60-Total.MVPA.time\n#### Long Bouts+Sporadic.time runs\nLong.Bouts.and.Sporadic.run<- rle(ifelse( one.minute.mat[,2]>=3,1,0))\nTotal.Number.of.MVPA.Long.Bouts.and.Sporadic<-  length(which(Long.Bouts.and.Sporadic.run$values==1))\n\nrun.for.Long.Bouts.and.Sporadic.mvpa<- Long.Bouts.and.Sporadic.run$lengths[which(Long.Bouts.and.Sporadic.run$values==1)]/ (60/mvpa.sporadic.interval) ###by hours ###point 7\n\nif(Total.MVPA.time==0)  Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.2<-0 else  Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.2<-100*length(run.for.Long.Bouts.and.Sporadic.mvpa[run.for.Long.Bouts.and.Sporadic.mvpa>1/30])/Total.Number.of.MVPA.Long.Bouts.and.Sporadic\nif(Total.MVPA.time==0)  Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.5<-0 else  Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.5<-100*length(run.for.Long.Bouts.and.Sporadic.mvpa[run.for.Long.Bouts.and.Sporadic.mvpa>1/12])/Total.Number.of.MVPA.Long.Bouts.and.Sporadic\nif(Total.MVPA.time==0)  Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.10<-0 else Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.10<-100*length(run.for.Long.Bouts.and.Sporadic.mvpa[run.for.Long.Bouts.and.Sporadic.mvpa>1/6])/Total.Number.of.MVPA.Long.Bouts.and.Sporadic\n\n\n#### Long Bouts Only runs\nrun.for.mvpa<-rle(ten.minute.collection$mvpa)\n\nTotal.Number.of.MVPA.Long.Bouts<-  length(which(run.for.mvpa$values==1))\ntemp.mvpa.long.bout<-run.for.mvpa$lengths[which(run.for.mvpa$values==1)]/6 ###by hours\nif(Total.Number.of.MVPA.Long.Bouts==0) Mean.MVPA.Long.Bout.Length<-0 else Mean.MVPA.Long.Bout.Length<-mean(temp.mvpa.long.bout)\n####   \nif(Total.Number.of.MVPA.Long.Bouts==0)  Proportion.of.MVPA.Long.Bouts.greater.10<-0 else  Proportion.of.MVPA.Long.Bouts.greater.10<-100*length(temp.mvpa.long.bout[temp.mvpa.long.bout>1/6])/Total.Number.of.MVPA.Long.Bouts\nif(Total.Number.of.MVPA.Long.Bouts==0)  Proportion.of.MVPA.Long.Bouts.greater.20<-0 else  Proportion.of.MVPA.Long.Bouts.greater.20<-100*length(temp.mvpa.long.bout[temp.mvpa.long.bout>2/6])/Total.Number.of.MVPA.Long.Bouts\n#### percentile is not meaningful, always too short\n####if(Total.Number.of.MVPA.Long.Bouts==0)\n#### {\n####percentile.MVPA.Long.Bouts.time.5<- 0\n####percentile.MVPA.Long.Bouts.time.25<- 0\n####percentile.MVPA.Long.Bouts.time.50<- 0\n####percentile.MVPA.Long.Bouts.time.75<- 0\n####percentile.MVPA.Long.Bouts.time.95<- 0\n#### } else {\n####  Percentiles.of.MVPA.Long.Bout.Length.quantile<- quantile(temp.mvpa.long.bout, probs = c(0.05,0.25,0.5,0.75,0.95)) \n####percentile.MVPA.Long.Bouts.time.5<- Percentiles.of.MVPA.Long.Bout.Length.quantile[1]\n####percentile.MVPA.Long.Bouts.time.25<- Percentiles.of.MVPA.Long.Bout.Length.quantile[2]\n####percentile.MVPA.Long.Bouts.time.50<- Percentiles.of.MVPA.Long.Bout.Length.quantile[3]\n####percentile.MVPA.Long.Bouts.time.75<- Percentiles.of.MVPA.Long.Bout.Length.quantile[4]\n####percentile.MVPA.Long.Bouts.time.95<- Percentiles.of.MVPA.Long.Bout.Length.quantile[5]\n####        }\n\n\n#################################################### \n#################################################### MET.value\n#################################################### \nHighest.MET.value.15s<- max(one.minute.mat[,2])\nHighest.MET.value.10min<- max(ten.minute.collection[,3])\n################################################ MET.value from MVPA\nTotal.MET.hrs.Long.Bouts.and.Sporadic.mvpa<- sum((one.minute.mat[,2]/60/60*one.minute.mat[,4])[one.minute.mat[,2]>=3])\nTotal.MET.hrs.Long.Bouts<- sum((subset(ten.minute.collection,mvpa==1))$mets/60*10)\n\n\ntable5<- c(88888888,Total.light.time,Total.MVPA.time, Total.MVPA.Long.Bout.time,Total.MVPA.Sporadic.time,Total.Number.of.MVPA.Long.Bouts.and.Sporadic,Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.2,Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.5,Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.10, Total.Number.of.MVPA.Long.Bouts,Mean.MVPA.Long.Bout.Length, Proportion.of.MVPA.Long.Bouts.greater.10,Proportion.of.MVPA.Long.Bouts.greater.20, Highest.MET.value.15s,Highest.MET.value.10min, Total.MET.hrs.Long.Bouts.and.Sporadic.mvpa,Total.MET.hrs.Long.Bouts)\ntable5.label<- c(\"88888888\",\"Total.light.time\",\"Total.MVPA.time\",\"Total.MVPA.Long.Bout.time\",\"Total.MVPA.Sporadic.time\",\"Total.Number.of.MVPA.Long.Bouts.and.Sporadic\",\"Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.2\",\"Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.5\",\"Proportion.of.MVPA.Long.Bouts.and.Sporadic.greater.10\",\"Total.Number.of.MVPA.Long.Bouts\",\"Mean.MVPA.Long.Bout.Length\",\"Proportion.of.MVPA.Long.Bouts.greater.10\",\"Proportion.of.MVPA.Long.Bouts.greater.20\",\"Highest.MET.value.15s\",\"Highest.MET.value.10min\",\"Total.MET.hrs.Long.Bouts.and.Sporadic.mvpa\",\"Total.MET.hrs.Long.Bouts\")\n###################################################\n###################################################\n################################################### For Sum Table \n###################################################\ntemp.Summary.Statistics.Table<- t(c(table1,table2,table3,table4,table5))\ncolnames(temp.Summary.Statistics.Table)<-c(table1.label,table2.label,table3.label,table4.label,table5.label)\n\n Summary.Statistics.Table<-rbind(Summary.Statistics.Table,temp.Summary.Statistics.Table)\n}\n \n}\n\nsetwd(folder.to.export.APST.csvfile.and.RDatafile)\nif(week==0)write.table(Summary.Statistics.Table, file =\"Summary.Statistics.Table.csv\", append=T, sep=',', row.names = F) \nif(week>0)write.table(Summary.Statistics.Table, file =\"Summary.Statistics.Table.csv\", append=T, sep=',',col.names=F, row.names = F) \n\nrm(list= ls()[grep(\"APST\", ls(),invert=T )])\n\n\n}\n\neval(parse(text=paste(\"save.image('Combine.RData')\",sep=\"\")))\n\n",
    "created" : 1448582299790.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4282546510",
    "id" : "97C64C6",
    "lastKnownWriteTime" : 1448305301,
    "path" : "C:/Yukun/Sarah'sProject_Haocheng/PCAdata_buildRData_V6.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}